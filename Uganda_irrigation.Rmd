---
title: Uganda's water landscape -- Spatial predictions of smallholder irrigation and the commonly associated crops
author: V. Modi, H. Siddiqui and M.G. Walsh
date: "`r format(Sys.time(), '%d, %B, %Y')`"
output:
  html_document:
    toc: true
    toc_depth: 2
    fig_caption: true
    keep_md: true
    number_sections: true
    css: style1.css
---

```{r, echo = FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
```

# Introduction

Irrigation plays a vital role in shaping the agricultural landscapes of Africa, a continent known for its diverse ecosystems, climatic variations, and farming challenges. With a rapidly growing population and unpredictable weather patterns exacerbated by climate change, the importance of irrigation in Africa cannot be overstated. 

* Irrigation will be essential for improving food security in Africa. Rain-fed agriculture remains susceptible to droughts and erratic rainfall, often leading to crop failures, food shortages, and poor nutritional quality produce. By providing controlled water supplies to crops, irrigation mitigates the risks associated with climatic uncertainties. Consistent water access allows for multiple cropping seasons, improved crop yields, and a diversified range of crops.

* Irrigation contributes to economic growth and/or poverty alleviation. Agriculture remains the mainstay of African economies, employing a large portion of the population. Improved irrigation systems can increase agricultural productivity, potentially leading to surplus produce that may be sold in local and international markets. This generates farmer income and stimulates economic growth at various levels, from rural communities to national economies.

* Irrigation can play a crucial role in environmental sustainability. Sustainable irrigation practices can lead to efficient water usage, preventing over-extraction of groundwater and reducing the strain on natural water sources. Properly managed irrigation can minimize soil erosion and degradation, preserving soil quality for future generations. Additionally, irrigation opens opportunities for controlled water management, enabling the cultivation of crops that are generally well-suited to local conditions, but which may not thrive under rain-fed agriculture.

* However, it is important to note that while irrigation offers numerous benefits, it should be managed carefully. Improper irrigation practices can lead to waterlogging, salinization, and environmental degradation. It is crucial to implement evidence-based, sustainable irrigation practices, embracing modern technology and knowledge sharing to ensure the responsible use of water resources.

The main objectives of this notebook are to introduce R code for labeling, exploration and discovery of the spatial distribution of smallholder irrigation and the commonly associated crops in Uganda. This markdown notebook is maintained on [Github](https://github.com/mgwalsh/QSEL/blob/main/Uganda_irrigation.Rmd), and you can fork and alter it from there for your reference and use.

# Data setup

The irrigation and crop observation data we shall be using were generated by the ... . To actually run this notebook, you will need to install and load the R-packages indicated in the chunk directly below.

```{r}
# Package names
packages <- c("tidyverse", "htmlwidgets", "leaflet", "DT", "rgdal", "raster", "doParallel", "caret", 
              "caretEnsemble", "randomForest", "xgboost", "glmnet", "pROC", "caTools")

# Install packages
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  utils::install.packages(packages[!installed_packages])
}

# Load packages
invisible(lapply(packages, library, character.only = TRUE))
```

## Load field survey data

The next chunk loads the irrigation and crop survey data from your working directory. Note that at the time of the writing of this notebook these data are not publicly available. ...

```{r, results = 'hide'}
plots <- read.table("UG_irrigated_plots.csv", header = T, sep = ",")
plots$irrigated <- ifelse(plots$ir1 == 'yes' & plots$ws1 == 'yes', 'a', 'b') ## a = irrigated, b = not irrigated
plots$irrigated <- as.factor(plots$irrigated)
crops <- read.table("UG_irrigated_crops.csv", header = T, sep = ",")
crops$onion.1 <- NULL ## removes the duplicated onion column
irdat <- merge(plots, crops, by="sid")
# irdat <- irdat[!duplicated(irdat[,4]), ] ## removes observations that have identical time stamps
```

An overview map of where the (non-duplicated) irrigation observations were collected in Uganda is generated by the next chunk. You can click and zoom into the individual locations that have been recorded thus far. Irrigated locations are shown in blue and the non-irrigated locations are shown in red.

```{r}
col <- ifelse(irdat$irrigated == TRUE, "blue", "red")

# CropScout sample locations
w <- leaflet() %>%
  setView(lng = mean(irdat$lon), lat = mean(irdat$lat), zoom = 7) %>%
  addProviderTiles(providers$OpenStreetMap.Mapnik) %>%
  addCircleMarkers(irdat$lon, irdat$lat,
                   color = col,
                   stroke = FALSE,
                   fillOpacity = 0.8,
                   radius = 5,
                   clusterOptions = markerClusterOptions(maxClusterRadius = 30))

saveWidget(w, 'UG_irrigation_locs.html', selfcontained = T) ## save leaflet map
w ## plot widget 
```

## Load and extract raster features

You can download all of the raster files that are needed for running the next chunks from our OSF repository [here](https://osf.io/ehsyg). Place the *.zip file into a directory called ./grids.

```{r}
# Unzip files into a sub-directory called "grids"
dir.create("grids", showWarnings=F)

# Load rasters
glist <- list.files(path="./grids", pattern="tif", full.names = T)
grids <- stack(glist)

# Survey variable selection and projection
vars <- c("sid", "lon", "lat", "s2", "s3", "ir1", "ws1", "irrigated", "tomato", "cabbage", "eggplant",
          "greens", "peppers", "pulses", "onion", "nuts", "banana", "melon", "passion", "taro", "potato",
          "beans", "cane", "sunflower", "papaya", "pineapple", "rice")
irdat <- irdat[vars] ## select variables

ir.proj <- project(cbind(irdat$lon, irdat$lat), "+proj=laea +ellps=WGS84 +lon_0=20 +lat_0=5
                                 +units=m +no_defs")
colnames(ir.proj) <- c("x","y")
irdat <- cbind(irdat, ir.proj)
coordinates(irdat) <- ~x+y
projection(irdat) <- projection(grids)

# Extract gridded variables at survey locations
irgrid <- extract(grids, irdat)
irdat <- as.data.frame(cbind(irdat, irgrid))
# irdat <- irdat %>% 
  mutate_at('LCCS', as.factor) %>%
  rename(
    MLAT = mlat.PERMANENT,
    MLON = mlon.PERMANENT)
```

The pre-processed Uganda raster data (in the `grids` raster stack) we will be using were derived and projected (to CRS = +proj=laea +ellps=WGS84 +lon_0=20 +lat_0=5 +units=m +no_defs) from their primary open sources. Short descriptions of the 34 included rasters are listed in the table below. We will also be using the most recent [GeoSurvey](https://geosurvey.qed.ai/) based land cover map of Uganda. You can find out how the constituent layers of this map were predicted by downloading the AfSIS land cover classification notebook from our OSF repository [here](https://osf.io/shkxp/).

```{r lccs_legend, echo=FALSE, fig.align="center", fig.cap="**Figure ??:** GeoSurvey-based land cover map and area estimates for Uganda (2020).", out.width = '80%'}

knitr::include_graphics("LCCS.png")
```

Note that the areas highlighted by the red boxes in the legend of Figure ?? are of primary interest here because they identify the main four cropland cover types in the country. Any irrigated croplands would therefore be a subset of these 4 types.

```{r, echo = FALSE}
rm(list=setdiff(ls(), c("irdat", "grids"))) ## scrubs extraneous objects in memory
```

# Predicting irrigation

We will be using a **stacked generalization** approach ([Wolpert, 1992](http://machine-learning.martinsewell.com/ensembles/stacking/Wolpert1992.pdf)), which is an ensemble learning technique that aims to improve the accuracy of predictions by combining multiple MLAs. Instead of relying on a single model's output, stacking trains a meta-model using the predictions of several base-models. The basic workflow in our context is as follows:

* **Split the data**: into representative training (calibration) and test (validation) sets.

* **Base-model training**: Train multiple base-models on the calibration set with J-fold cross-validation. Use the trained base-models to predict the labels from the original features. These predictions become the "meta-features" for the next layer in the stacked model.

* **Model stacking** Stack on the meta-features, using the validation set's labels as the target ... with J-fold cross-validation.

* **Prediction**: Generate predictions for new data i.e., the 33 rasters (`grids`) in our case. The stacked-model then makes the final predictions based on these, rather than on the original features.

The intuition behind stacking is that while individual models may have particular strengths and weaknesses, a meta-model may be able to learn the best way to combine their predictions, to achieve better overall performance. Stacking has been shown to outperform other ensemble methods in various tasks, given a careful choice of features, base and meta-models ([Kaggle AI report, 2023](https://www.kaggle.com/AI-Report-2023)). 

## Data split

This first chunk sets an 80/20% calibration and validation partition. It is always best to do this as early as possible to avoid any [data leakage](https://en.wikipedia.org/wiki/Leakage_(machine_learning)). The function `createDataPartition` in the [`caret`](https://topepo.github.io/caret/index.html) package can be used to generate randomized splits of the data. If the argument to this function is a factor, random sampling occurs within each class and will preserve the overall class distribution of the data. We partition on the `irrigated` variable here.

```{r}
# Set calibration/validation set randomization seed
seed <- 12358
set.seed(seed)
irdat <- irdat[sample(1:nrow(irdat)), ] # randomize observations
irdat <- na.omit(irdat)

# Split data into calibration and validation sets
irIndex <- createDataPartition(irdat$irrigated, p = 4/5, list = F, times = 1)
ir_cal <- irdat[ irIndex,]
ir_val <- irdat[-irIndex,]

# Select calibration labels and gridded features
lcal <- ir_cal[ ,8]
fcal <- ir_cal[ ,c(28:41, 43:61)]

# Select validation labels and gridded features
lval <- ir_val[ ,8]
fval <- ir_val[ ,c(28:41, 43:61)]
```

## Base-model training

This chunk fits 3 base-models using the gridded calibration data with 10-fold cross-validation. Learn more about how these MLAs work by following links at: [randomForest](https://www.rdocumentation.org/packages/randomForest/versions/4.6-14/topics/randomForest), [xgboost](https://www.kaggle.com/rtatman/machine-learning-with-xgboost-in-r/),
and [glmnet](https://www.rdocumentation.org/packages/glmnet/versions/4.1-8/topics/glmnet). The 3 base-models represent some of the main approaches to ML with tabular data ([Kaggle AI report, 2023](https://www.kaggle.com/AI-Report-2023)) i.e., [bootstrap aggregation](https://en.wikipedia.org/wiki/Bootstrap_aggregating), [gradient boosting](https://en.wikipedia.org/wiki/Gradient_boosting), and [L1/L2 regularization](https://medium.com/analytics-vidhya/regularization-understanding-l1-and-l2-regularization-for-deep-learning-a7b9e4a409bf). You can use `caretEnsemble` instead of `caret` as long as the feature variables (the `grids` in this case), and the `trainControl` methods are the same for each model in the `caretList` function. This shortens the length of this notebook but does not otherwise affect overall `caret` functionality. Note however that the calculations take a bit of time to run on a normal 8-core, 16 Gb memory computer, even when engaging all 8 cores. We initially fit the models with default-tuning of the relevant [hyperparameters](https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)). Should the need arise, we can always do more fine-tuning later.

```{r, results = 'hide'}
dir.create("learners", showWarnings = FALSE)

# Start doParallel
seed <- 12358
set.seed(seed)
mc <- makeCluster(detectCores())
registerDoParallel(mc)

# Specify model training controls
tc <- trainControl(method = "cv", number = 10, classProbs = TRUE,
                   summaryFunction = twoClassSummary, allowParallel = TRUE, savePredictions = "final")

# Train 3 base learners using the calibration set
blist <- caretList(fcal, lcal,
                   trControl = tc,
                   tuneList = NULL,
                   methodList = c("rf", "xgbTree", "glmnet"),
                   metric = "ROC")

# Generate predictions for the validation set
preds <- as.data.frame(predict(blist, newdata = fval))

# Save fitted model objects
stopCluster(mc)
fname <- paste("./learners/", "base_blist.rds", sep = "")
saveRDS(blist, fname)
```

## Model stacking

```{r, results =  'hide'}
# Start doParallel
set.seed(seed)
mc <- makeCluster(detectCores())
registerDoParallel(mc)

# Specify model training controls
tc <- trainControl(method = "cv", number = 10, classProbs = TRUE, allowParallel = TRUE,
                   summaryFunction = twoClassSummary, savePredictions = "final")

# Stack the 3 base classifiers using the validation set
glm_stack <- train(preds, lval,
                   trControl = tc,
                   tuneList = NULL,
                   method = "glmnet",
                   family = "binomial",
                   metric = "ROC")

preds$stack <- predict(glm_stack, newdata = preds, type = "prob")
caTools::colAUC(preds, lval)

# Save fitted model objects
stopCluster(mc)
fname <- paste("./learners/", "glm_stack.rds", sep = "")
saveRDS(glm_stack, fname)
```

## Spatial predictions

```{r}
dir.create("maps")

# Generate spatial predictions
rfo.map <- predict(grids, blist$rf, type = "prob")
xgb.map <- predict(grids, blist$xgbTree, type = "prob")
glm.map <- predict(grids, blist$glmnet, type = "prob")
spreds <- stack(rf.map, xt.map, gl.map)
names(spreds) <- c("rf","xgbTreet", "glmnet")
sta.map <- predict(spreds, glm_stack, type = "prob")

# Write out geotif files
```

## Small area estimation of irrigation

# Predicting irrigated crops

## Base-model training

## Model stacking

# Main takeaways


